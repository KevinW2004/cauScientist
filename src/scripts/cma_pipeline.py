"""
ä¸»è¿è¡Œæµç¨‹
CMA Pipeline - å®Œæ•´ç‰ˆ
åŒæ—¶æ”¯æŒ:
1. æœ¬åœ°æ¨¡å‹ / OpenAI API åˆ‡æ¢
2. æ•°æ®åŠ è½½åŠŸèƒ½
3. çœŸå®å›¾å¯¹æ¯”è¯„ä¼°
"""
import json
import numpy as np
import os
from typing import Dict, List

from llm_hypothesis import LLMHypothesisGenerator
from post_processing import PostProcessor
from data_loader import CausalDataset, DOMAIN_CONTEXTS
from utils.score_functions import score_graph_with_bic
from transformers import AutoTokenizer

from utils import ConfigManager
from utils.metrics import compute_metrics
from llm_loader import LLMLoader, LLMLoaderFactory

os.environ['VLLM_ATTENTION_BACKEND'] = 'FLASH_ATTN'

class CMAPipeline:
    """CMAå®Œæ•´æµç¨‹ç®¡ç†å™¨ - æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œæ•°æ®åŠ è½½"""
    
    def __init__(
        self,
        # æ•°æ®å‚æ•° - ä¸‰é€‰ä¸€
        domain_name: str = None,
        variable_list: List[str] = None,
        data: np.ndarray = None,
        dataset: CausalDataset = None,  # æ–°å¢: ç›´æ¥ä¼ å…¥æ•°æ®é›†
        domain_context: str = "",
        use_observational_only: bool = True,  # æ–°å¢: æ˜¯å¦åªç”¨è§‚æµ‹æ•°æ®
    ):
        """
        åˆå§‹åŒ–CMAæµç¨‹
        
        Args:
            # æ–¹å¼1: æ‰‹åŠ¨æŒ‡å®šæ•°æ®
            domain_name: é¢†åŸŸåç§°
            variable_list: å˜é‡åˆ—è¡¨
            data: æ•°æ® [n_samples, n_variables]
            domain_context: é¢†åŸŸèƒŒæ™¯çŸ¥è¯†
            
            # æ–¹å¼2: ä¼ å…¥CausalDatasetå¯¹è±¡
            dataset: CausalDatasetå¯¹è±¡(åŒ…å«æ•°æ®ã€çœŸå®å›¾ã€å˜é‡åç­‰)
            use_observational_only: æ˜¯å¦åªä½¿ç”¨è§‚æµ‹æ•°æ®(æ’é™¤å¹²é¢„æ ·æœ¬)
            
            # è¾“å‡ºé…ç½®
            output_dir: è¾“å‡ºç›®å½•
            device: æ¨¡å‹æ‹Ÿåˆè®¾å¤‡
        """
        self.config = ConfigManager()
        config = self.config
        self.output_dir = config.get("experiment.output.dir", "./cma_output")
        os.makedirs(self.output_dir, exist_ok=True)
        self.device = config.get("llm.local.device", "cuda")
        self.llm_type = config.get("llm.type")
        
        # ===== å¤„ç†æ•°æ®è¾“å…¥(ä¸¤ç§æ–¹å¼) =====
        if dataset is not None:
            # æ–¹å¼2: ä½¿ç”¨CausalDataset
            self.dataset = dataset
            self.domain_name = dataset.domain_name
            self.variable_list = dataset.variable_names
            
            # é€‰æ‹©ä½¿ç”¨å…¨éƒ¨æ•°æ®è¿˜æ˜¯åªç”¨è§‚æµ‹æ•°æ®
            if use_observational_only and dataset.interventions is not None:
                self.data = dataset.get_observational_data()
                print(f"[Info] Using observational data only: {self.data.shape}")
            else:
                self.data = dataset.data
                print(f"[Info] Using all data: {self.data.shape}")
            
            # ä½¿ç”¨é¢„å®šä¹‰çš„é¢†åŸŸèƒŒæ™¯
            if not domain_context:
                self.domain_context = DOMAIN_CONTEXTS.get(dataset.domain_name, "")
            else:
                self.domain_context = domain_context
                
        else:
            # æ–¹å¼1: æ‰‹åŠ¨æŒ‡å®š
            if domain_name is None or variable_list is None or data is None:
                raise ValueError(
                    "Either provide 'dataset' OR all of ('domain_name', 'variable_list', 'data')"
                )
            
            self.dataset = None
            self.domain_name = domain_name
            self.variable_list = variable_list
            self.data = data
            self.domain_context = domain_context
        
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        if self.dataset:
            self._save_dataset_info()
        
        # ===== é›†ä¸­åŠ è½½LLM =====
        llm_type = config.get("llm.type")
        print("\n" + "="*70)
        print("INITIALIZING LLM BACKEND")
        print("="*70)
        print(f"LLM Type: {llm_type}")
        self.llm_loader: LLMLoader = LLMLoaderFactory.create_llm_loader(llm_type)
        self.llm_loader.load_model()

        # ç»Ÿä¸€æ³¨å…¥ llm_loader åˆ° hypothesis generator å’Œ post processor
        self.hypothesis_generator = LLMHypothesisGenerator(llm_loader=self.llm_loader)
        # self.post_processor = PostProcessor(llm_loader=self.llm_loader)
        
        # å­˜å‚¨å†å²
        self.iteration_history = []
        
        print("âœ“ Pipeline initialized successfully!")
        print("="*70 + "\n")
    
    def _save_dataset_info(self):
        """ä¿å­˜æ•°æ®é›†ä¿¡æ¯(ä»…å½“æœ‰datasetæ—¶)"""
        info = {
            "domain": self.dataset.domain_name,
            "n_variables": self.dataset.n_variables,
            "n_samples_total": self.dataset.n_samples,
            "n_samples_used": len(self.data),
            "variable_names": self.dataset.variable_names,
            "ground_truth_edges": self.dataset.get_ground_truth_edges(),
            "intervention_summary": self.dataset.get_intervention_summary()
        }
        
        info_path = os.path.join(self.output_dir, "dataset_info.json")
        with open(info_path, 'w') as f:
            json.dump(info, f, indent=2)
        print(f"[Info] Dataset info saved to {info_path}")

    
    def run(
        self,
        verbose: bool = True
    ) -> Dict:
        """è¿è¡Œå®Œæ•´çš„CMAæµç¨‹"""
        num_iterations = self.config.get("experiment.training.num_iterations", 3)
        
        print("\n" + "="*70)
        print(f"STARTING CMA PIPELINE: {self.domain_name.upper()}")
        print("="*70)
        
        # æ‰“å°æ•°æ®é›†æ‘˜è¦
        if self.dataset:
            self.dataset.print_summary()
        else:
            print(f"Variables: {len(self.variable_list)}")
            print(f"Data shape: {self.data.shape}")
        
        print(f"LLM Type: {self.llm_type}")
        print(f"Iterations: {num_iterations}")
        print(f"Output directory: {self.output_dir}")
        print("="*70 + "\n")
        
        previous_graph = None
        previous_results = None
        memory = None
        best = None
        t = 0
        
        for i in range(num_iterations):
            print("\n" + "ğŸ”„ "*35)
            print(f"ITERATION {t}")
            print("ğŸ”„ "*35)
            
            # ===== æ­¥éª¤1: å‡è®¾ç”Ÿæˆ  =====
            structured_graph = self.hypothesis_generator.generate_hypothesis(
                variable_list=self.variable_list,
                domain_name=self.domain_name,
                domain_context=self.domain_context,
                previous_graph=previous_graph,
                memory=memory,
                iteration=t,
                num_edge_operations=3
            )
            if structured_graph is None:
                continue
            
            if verbose:
                self.hypothesis_generator.visualize_graph(structured_graph)
            
            # ä¿å­˜å‡è®¾
            graph_path = os.path.join(self.output_dir, f"graph_t{t}.json")
            with open(graph_path, 'w') as f:
                json.dump(structured_graph, f, indent=2)
            
            # ===== æ­¥éª¤2: ä½¿ç”¨æ ‡å‡† BIC è¯„åˆ† =====
            fitting_results = score_graph_with_bic(
                structured_graph=structured_graph,
                data=self.data,
                variable_names=self.variable_list
            )
            
            # å°†è¯„åˆ†ç»“æœæ·»åŠ åˆ°å›¾çš„å…ƒæ•°æ®
            structured_graph['metadata']['log_likelihood'] = fitting_results['cv_log_likelihood']
            structured_graph['metadata']['bic'] = fitting_results['bic']
            structured_graph['metadata']['num_parameters'] = fitting_results['num_parameters']
            structured_graph['metadata']['method'] = fitting_results['method']
            
            # ===== æ­¥éª¤3: åå¤„ç† - ç”Ÿæˆè®°å¿† =====
            # memory = self.post_processor.generate_memory(
            #     current_graph=structured_graph,
            #     current_results=fitting_results,
            #     previous_graph=previous_graph,
            #     previous_results=previous_results,
            #     domain_name=self.domain_name,
            #     model=llm_model_name,
            #     temperature=temperature,
            #     max_tokens=max_tokens
            # )
            
            # print("\n" + "-"*70)
            # print("MEMORY (Î¼_t):")
            # print("-"*70)
            # print(memory)
            # print("-"*70)
            
            # # ä¿å­˜è®°å¿†
            # memory_path = os.path.join(self.output_dir, f"memory_t{t}.txt")
            # self.post_processor.save_memory(memory, memory_path)
            
            # ===== è®°å½•å†å² =====
            self.iteration_history.append({
                'iteration': t,
                'graph': structured_graph,
                'results': fitting_results,
                # 'memory': memory,
                'metrics':compute_metrics(self, structured_graph)
            })
            
            # ===== æ›´æ–°å‰ä¸€è½®çš„ä¿¡æ¯ =====
            previous_graph = structured_graph
            previous_results = fitting_results
            
            # ===== è¯„ä¼°ä¸çœŸå®å›¾çš„å·®è·(å¦‚æœæœ‰) =====
            if self.dataset and verbose:
                self._evaluate_against_ground_truth(structured_graph)
            
            # ===== æå‰ç»ˆæ­¢æ£€æŸ¥ =====
            if t > 0:
                ll_change = (fitting_results['cv_log_likelihood'] - 
                           self.iteration_history[t-1]['results']['cv_log_likelihood'])
                
                if abs(ll_change) < 0.01:
                    print(f"\nâš ï¸  Convergence detected (Î”LL={ll_change:.4f}). Stopping early.")
                    break
            t += 1
        
        # ===== ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š =====
        final_report = self._generate_final_report()
        
        report_path = os.path.join(self.output_dir, "final_report.txt")
        with open(report_path, 'w') as f:
            f.write(final_report)
        
        print("\n" + "="*70)
        print("CMA PIPELINE COMPLETED")
        print("="*70)
        print(final_report)
        print("="*70 + "\n")
        
        return self.iteration_history[-1] if len(self.iteration_history[-1])!= 0 else None
    
    def _evaluate_against_ground_truth(self, predicted_graph: Dict):
        """è¯„ä¼°é¢„æµ‹å›¾ä¸çœŸå®å›¾çš„å·®è·"""
        
        # æå–é¢„æµ‹çš„è¾¹
        predicted_edges = set()
        for node in predicted_graph['nodes']:
            child = node['name']
            for parent in node.get('parents', []):
                parent_idx = self.variable_list.index(parent)
                child_idx = self.variable_list.index(child)
                predicted_edges.add((parent_idx, child_idx))
        
        # æå–çœŸå®çš„è¾¹
        true_edges = set()
        for i in range(self.dataset.n_variables):
            for j in range(self.dataset.n_variables):
                if self.dataset.ground_truth_graph[i, j] == 1:
                    true_edges.add((i, j))
        
        # è®¡ç®—æŒ‡æ ‡
        true_positive = len(predicted_edges & true_edges)
        false_positive = len(predicted_edges - true_edges)
        false_negative = len(true_edges - predicted_edges)
        
        precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0
        recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        print("\n" + "-"*70)
        print("EVALUATION AGAINST GROUND TRUTH:")
        print("-"*70)
        print(f"True Positive (correct edges): {true_positive}")
        print(f"False Positive (incorrect edges): {false_positive}")
        print(f"False Negative (missing edges): {false_negative}")
        print(f"Precision: {precision:.3f}")
        print(f"Recall: {recall:.3f}")
        print(f"F1 Score: {f1:.3f}")
        
        if false_positive > 0:
            print(f"\nIncorrect edges added:")
            for parent_idx, child_idx in (predicted_edges - true_edges):
                print(f"  {self.variable_list[parent_idx]} â†’ {self.variable_list[child_idx]}")
        
        if false_negative > 0:
            print(f"\nMissing edges:")
            for parent_idx, child_idx in (true_edges - predicted_edges):
                print(f"  {self.variable_list[parent_idx]} â†’ {self.variable_list[child_idx]}")
        
        print("-"*70)
    
    def _generate_final_report(self) -> str:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        
        lines = [
            f"CMA Final Report: {self.domain_name}",
            "="*70,
        ]
        
        # æ•°æ®é›†ä¿¡æ¯
        if self.dataset:
            lines.extend([
                f"\nDataset Information:",
                f"  Variables: {self.dataset.n_variables}",
                f"  Samples used: {len(self.data)}",
                f"  Ground truth edges: {self.dataset.ground_truth_graph.sum()}",
            ])
        else:
            lines.extend([
                f"\nVariables: {len(self.variable_list)}",
                f"Data samples: {self.data.shape[0]}",
            ])
        
        lines.extend([
            f"\nTotal iterations: {len(self.iteration_history)}",
            "\n" + "-"*70,
            "Iteration Summary:",
            "-"*70
        ])
        
        for record in self.iteration_history:
            t = record['iteration']
            ll = record['results']['cv_log_likelihood']
            edges = record['graph']['metadata']['num_edges']
            lines.append(f"  t={t}: LL={ll:.4f}, Edges={edges}")
        
        # æœ€ä½³è¿­ä»£
        if len(self.iteration_history) > 0:
            best_idx = max(range(len(self.iteration_history)), 
                        key=lambda i: self.iteration_history[i]['results']['cv_log_likelihood'])
            best_ll = self.iteration_history[best_idx]['results']['cv_log_likelihood']
        
            lines.extend([
                "\n" + "-"*70,
                f"Best iteration: t={best_idx} (LL={best_ll:.4f})",
                "-"*70,
                "\nFinal Causal Structure:"
            ])
            
            final_graph = self.iteration_history[-1]['graph']
            for node in final_graph['nodes']:
                parents = node.get('parents', [])
                if parents:
                    for parent in parents:
                        lines.append(f"  {parent} â†’ {node['name']}")
                else:
                    lines.append(f"  {node['name']} (root)")
        
        # å¦‚æœæœ‰çœŸå®å›¾,æ·»åŠ å¯¹æ¯”
        if self.dataset:
            lines.extend([
                "\n" + "-"*70,
                "Ground Truth Structure:"
            ])
            for edge in self.dataset.get_ground_truth_edges():
                lines.append(f"  {edge[0]} â†’ {edge[1]}")
        
        return "\n".join(lines)
    
    def get_best_graph(self) -> Dict:
        """è¿”å›æ‹Ÿåˆåº¦æœ€å¥½çš„å›¾"""
        best_idx = max(range(len(self.iteration_history)),
                       key=lambda i: self.iteration_history[i]['results']['cv_log_likelihood'])
        return self.iteration_history[best_idx]['graph']
    